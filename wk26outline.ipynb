{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU54vdySQAaFbKIT/uEDSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahsawar51/MY_DATA_SCIENCE_JOURNEY/blob/main/wk26outline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the content in a professional format:\n",
        "\n",
        "---\n",
        "\n",
        "# **Week 26: Feature Selection**\n",
        "\n",
        "## **Session 54: Feature Selection Part 1**\n",
        "\n",
        "### **What is Feature Selection?**\n",
        "- Introduction to the concept and significance of selecting relevant features in a dataset to improve model performance and reduce complexity.\n",
        "\n",
        "### **Why Perform Feature Selection?**\n",
        "- Discuss the importance of reducing dimensionality, enhancing model accuracy, and improving computational efficiency.\n",
        "\n",
        "### **Types of Feature Selection**\n",
        "- Overview of various methods used for selecting important features.\n",
        "\n",
        "#### **Filter-Based Feature Selection**\n",
        "- Feature selection based on statistical tests or metrics independent of any machine learning algorithm.\n",
        "\n",
        "#### **Duplicate Features**\n",
        "- Identifying and eliminating redundant features that provide no additional information.\n",
        "\n",
        "#### **Variance Threshold**\n",
        "- Removing features with low variance, as they are unlikely to carry useful information.\n",
        "\n",
        "#### **Correlation**\n",
        "- Eliminating features that are highly correlated to avoid multicollinearity.\n",
        "\n",
        "#### **ANOVA**\n",
        "- Using analysis of variance to determine whether there are significant differences between groups of data.\n",
        "\n",
        "#### **Chi-Square**\n",
        "- A statistical test to examine the relationship between categorical features and the target variable.\n",
        "\n",
        "### **Advantages and Disadvantages**\n",
        "- Discuss the pros and cons of Filter-based methods.\n",
        "\n",
        "---\n",
        "\n",
        "## **Session 55: Feature Selection Part 2**\n",
        "\n",
        "### **Wrapper Method**\n",
        "- Feature selection methods that evaluate subsets of features based on model performance.\n",
        "\n",
        "### **Types of Wrapper Methods**\n",
        "- Exploring various strategies like exhaustive search and sequential methods.\n",
        "\n",
        "#### **Exhaustive Feature Selection/Best Subset Selection**\n",
        "- A method of evaluating all possible feature subsets to identify the optimal set.\n",
        "\n",
        "#### **Sequential Backward Selection (SBS)**\n",
        "- A step-by-step approach where features are removed one by one, and the model is re-evaluated after each removal.\n",
        "\n",
        "#### **Sequential Forward Selection (SFS)**\n",
        "- A method where features are added one by one, and the model is evaluated after each addition.\n",
        "\n",
        "### **Advantages and Disadvantages**\n",
        "- Evaluating the trade-offs of Wrapper methods.\n",
        "\n",
        "---\n",
        "\n",
        "## **Session 56: Feature Selection Part 3**\n",
        "\n",
        "### **Embedded Methods**\n",
        "- Feature selection methods that perform feature selection during model training, often through regularization techniques.\n",
        "\n",
        "#### **Linear Regression**\n",
        "- Using coefficients of a linear model to identify important features.\n",
        "\n",
        "#### **Tree-Based Models**\n",
        "- Decision trees and tree-based algorithms, such as Random Forests, for selecting important features based on splits.\n",
        "\n",
        "#### **Regularized Models**\n",
        "- Lasso and Ridge regression techniques that penalize less important features by shrinking their coefficients to zero.\n",
        "\n",
        "#### **Recursive Feature Elimination (RFE)**\n",
        "- A method that recursively removes features and builds a model on the remaining features to identify the most significant ones.\n",
        "\n",
        "### **Advantages and Disadvantages**\n",
        "- Analyzing the strengths and weaknesses of Embedded methods.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rWd4W1WBC90Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xr7idc7ODBW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}